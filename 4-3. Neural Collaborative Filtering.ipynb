{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86f61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82870cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from module import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea602b79",
   "metadata": {},
   "source": [
    "# 1. Data\n",
    "- 해당의 데이터는 movielens 데이터이며, train_test_split 으로 나누어져 훈련용, 시험용 데이터로 나누어진다.\n",
    "- generate_trainset, generate_testset 으로 인해 반환되는 값은 numpy array의 형식으로 X, y 로 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec438cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 shape : (80003, 2), 훈련 라벨 갯수 : 80003\n",
      "테스트 데이터 shape : (19259, 2), 테스트 라벨 갯수 : 19259\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "X_train, y_train = loader.generate_trainset()\n",
    "X_test, y_test = loader.generate_testset()\n",
    "\n",
    "print(\"훈련 데이터 shape : {}, 훈련 라벨 갯수 : {}\".format(X_train.shape, y_train.size))\n",
    "print(\"테스트 데이터 shape : {}, 테스트 라벨 갯수 : {}\".format(X_test.shape, y_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bb04c",
   "metadata": {},
   "source": [
    "# 2. Neural Collaborative Filtering (Neural CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8f354",
   "metadata": {},
   "source": [
    "## 1. Generate Neural CF Model Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb98d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setting Value\n",
    "\n",
    "# Global\n",
    "num_users = loader.num_users\n",
    "num_items = loader.num_items\n",
    "regs = 0\n",
    "\n",
    "# GMF Setting\n",
    "latent_features = 8\n",
    "\n",
    "# MLP Setting\n",
    "layers = list(map(int, [64,32,16,8]))\n",
    "num_layers = len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad44ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 입력 층 생성\n",
    "user_input = keras.Input(shape=(1,), dtype='int32')\n",
    "item_input = keras.Input(shape=(1,), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f1e7e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 사용자 X 아이템 ----\n",
      "입력 값: 0\n",
      "GMF 출력 값: [ 1.6539261e-05 -3.5399414e-04 -4.5457669e-04  1.1783070e-04\n",
      " -2.7766862e-04  4.4984816e-04 -2.1152396e-04 -1.0644225e-03]\n",
      "훈련 데이터 shape: (80003, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3-1. GMF Layer Group 생성 (embedding -> flatten -> multiply)\n",
    "user_model_gmf = keras.Sequential()\n",
    "item_model_gmf = keras.Sequential()\n",
    "\n",
    "user_model_gmf.add(user_input)\n",
    "item_model_gmf.add(item_input)\n",
    "\n",
    "# 3-1-1. embedding\n",
    "user_embedding_gmf = keras.layers.Embedding(\n",
    "                    num_users,\n",
    "                    latent_features,\n",
    "                    embeddings_regularizer=keras.regularizers.l2(regs),\n",
    "                    name='user_emebedding')\n",
    "item_embedding_gmf = keras.layers.Embedding(\n",
    "                    num_items,\n",
    "                    latent_features,\n",
    "                    embeddings_regularizer=keras.regularizers.l2(regs),\n",
    "                    name='item_emebedding')\n",
    "user_model_gmf.add(user_embedding_gmf)\n",
    "item_model_gmf.add(item_embedding_gmf)\n",
    "\n",
    "\n",
    "# 3-1-2. flatten\n",
    "user_latent_gmf = keras.layers.Flatten()\n",
    "item_latent_gmf = keras.layers.Flatten()\n",
    "user_model_gmf.add(user_latent_gmf)\n",
    "item_model_gmf.add(item_latent_gmf)\n",
    "\n",
    "# 3-1-3. multiply\n",
    "user_output_gmf = user_model_gmf(X_train[:, 0])\n",
    "item_output_gmf = item_model_gmf(X_train[:, 1])\n",
    "concat = keras.layers.Multiply()\n",
    "gmf_result = concat([user_output_gmf, item_output_gmf])\n",
    "\n",
    "print(\"---- 사용자 X 아이템 ----\")\n",
    "print(\"입력 값: {}\".format(X_train[0, 0], X_train[0, 1]))\n",
    "print(\"GMF 출력 값: {}\".format(gmf_result[0].numpy()))\n",
    "print(\"훈련 데이터 shape: {}\\n\".format(gmf_result.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00ae4ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 사용자 X 아이템 ----\n",
      "입력 값: 0\n",
      "MLP 출력 값: [0.00828632 0.         0.01420904 0.02250351 0.00087989 0.01574119\n",
      " 0.         0.00567012]\n",
      "훈련 데이터 shape: (80003, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3-2. MLP Layer Group 생성 (embedding -> flatten -> concatenate -> hidden layers)\n",
    "user_model_mlp = keras.Sequential()\n",
    "item_model_mlp = keras.Sequential()\n",
    "\n",
    "user_model_mlp.add(user_input)\n",
    "item_model_mlp.add(item_input)\n",
    "\n",
    "# 3-2-1. embedding\n",
    "user_embedding_mlp = keras.layers.Embedding(\n",
    "                    num_users,\n",
    "                    int(layers[0] / 2),\n",
    "                    embeddings_regularizer=keras.regularizers.l2(regs),\n",
    "                    name='user_emebedding')\n",
    "item_embedding_mlp = keras.layers.Embedding(\n",
    "                    num_items,\n",
    "                    int(layers[0] / 2),\n",
    "                    embeddings_regularizer=keras.regularizers.l2(regs),\n",
    "                    name='item_emebedding')\n",
    "user_model_mlp.add(user_embedding_mlp)\n",
    "item_model_mlp.add(item_embedding_mlp)\n",
    "\n",
    "# 3-2-2. flatten\n",
    "user_latent_mlp = keras.layers.Flatten()\n",
    "item_latent_mlp = keras.layers.Flatten()\n",
    "user_model_mlp.add(user_latent_mlp)\n",
    "item_model_mlp.add(item_latent_mlp)\n",
    "\n",
    "# 3-2-3. concatenate\n",
    "user_output_mlp = user_model_mlp(X_train[:, 0])\n",
    "item_output_mlp = item_model_mlp(X_train[:, 1])\n",
    "vector = keras.layers.Concatenate()\n",
    "concatenates_output = vector([user_output_mlp, item_output_mlp])\n",
    "\n",
    "# 3-2-4. hidden layers\n",
    "hidden_model = keras.Sequential()\n",
    "for index in range(num_layers):\n",
    "    hidden_layer = keras.layers.Dense(\n",
    "                    layers[index],\n",
    "                    kernel_regularizer=keras.regularizers.l2(regs),\n",
    "                    activation = keras.activations.relu,\n",
    "                    name = \"layer_{}\".format(index)\n",
    "                   )\n",
    "    hidden_model.add(hidden_layer)\n",
    "mlp_result = hidden_model(concatenates_output)\n",
    "\n",
    "print(\"---- 사용자 X 아이템 ----\")\n",
    "print(\"입력 값: {}\".format(X_train[0, 0], X_train[0, 1]))\n",
    "print(\"MLP 출력 값: {}\".format(mlp_result[0].numpy()))\n",
    "print(\"훈련 데이터 shape: {}\\n\".format(mlp_result.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23d3a324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- GMF X MLP ----\n",
      "입력 값: 0\n",
      "MLP 출력 값: [ 1.6539261e-05 -3.5399414e-04 -4.5457669e-04  1.1783070e-04\n",
      " -2.7766862e-04  4.4984816e-04 -2.1152396e-04 -1.0644225e-03\n",
      "  8.2863234e-03  0.0000000e+00  1.4209044e-02  2.2503514e-02\n",
      "  8.7989063e-04  1.5741188e-02  0.0000000e+00  5.6701186e-03]\n",
      "훈련 데이터 shape: (80003, 16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. concat GMF output and MLP output\n",
    "concat_neural = keras.layers.Concatenate()\n",
    "concat_neural = concat_neural([gmf_result, mlp_result])\n",
    "\n",
    "print(\"---- GMF X MLP ----\")\n",
    "print(\"입력 값: {}\".format(X_train[0, 0], X_train[0, 1]))\n",
    "print(\"MLP 출력 값: {}\".format(concat_neural[0].numpy()))\n",
    "print(\"훈련 데이터 shape: {}\\n\".format(concat_neural.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9daa3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Neural CF 는 GMF가 학습하는 선형적 관계와 MLP가 학습하는 비선형적 관계를 이용하여 학습한다. ----\n",
      "[[0.00469078]\n",
      " [0.00045272]\n",
      " [0.00077031]\n",
      " ...\n",
      " [0.00121713]\n",
      " [0.00384654]\n",
      " [0.00874607]]\n"
     ]
    }
   ],
   "source": [
    "# 5. Dense Layer\n",
    "output = keras.layers.Dense(1, kernel_initializer=keras.initializers.lecun_uniform(),name='output')\n",
    "result = output(concat_neural)\n",
    "\n",
    "print(\"---- Neural CF 는 GMF가 학습하는 선형적 관계와 MLP가 학습하는 비선형적 관계를 이용하여 학습한다. ----\")\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fae78",
   "metadata": {},
   "source": [
    "## 2. Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2829fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. model setting\n",
    "from model import NeuralMF\n",
    "model = NeuralMF(loader.num_users, loader.num_items).get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85d8b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Callbacks\n",
    "early_stop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# model_out_file = 'Pretrain/GMF_%s.h5' % (datetime.now().strftime('%Y-%m-%d-%h-%m-%s'))\n",
    "# model_check_cb = keras.callbacks.ModelCheckpoint(model_out_file, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46165c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compile\n",
    "learner = \"adam\"\n",
    "learning_rate = 0.001\n",
    "\n",
    "if learner == \"adagrad\":\n",
    "    model.compile(optimizer=keras.optimizers.Adagrad(learning_rate=learning_rate), loss='mse')\n",
    "elif learner == \"rmsprop\":\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate), loss='mse')\n",
    "elif learner == \"adam\":\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
    "else:\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 2.4469 - val_loss: 0.8103\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7629 - val_loss: 0.7966\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7145 - val_loss: 0.7891\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6361 - val_loss: 0.7778\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5429 - val_loss: 0.8062\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4784 - val_loss: 0.8177\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4336 - val_loss: 0.8443\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3998 - val_loss: 0.8686\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3727 - val_loss: 0.8889\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3489 - val_loss: 0.9097\n",
      "Epoch 11/20\n",
      "198/313 [=================>............] - ETA: 0s - loss: 0.3197"
     ]
    }
   ],
   "source": [
    "# 4. Train\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "\n",
    "history = model.fit(\n",
    "            [X_train[:, 0], X_train[:, 1]], y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=([X_test[:, 0], X_test[:, 1]], y_test),\n",
    "            callbacks=[early_stop_cb]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8e3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
